{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 285,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.17543859649122806,
      "grad_norm": 4.673953056335449,
      "learning_rate": 4.842105263157895e-05,
      "loss": 40.7813,
      "step": 10
    },
    {
      "epoch": 0.3508771929824561,
      "grad_norm": 5.696115970611572,
      "learning_rate": 4.666666666666667e-05,
      "loss": 40.5049,
      "step": 20
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 6.3789963722229,
      "learning_rate": 4.491228070175439e-05,
      "loss": 39.7687,
      "step": 30
    },
    {
      "epoch": 0.7017543859649122,
      "grad_norm": 6.480921268463135,
      "learning_rate": 4.3157894736842105e-05,
      "loss": 38.7007,
      "step": 40
    },
    {
      "epoch": 0.8771929824561403,
      "grad_norm": 7.537936687469482,
      "learning_rate": 4.140350877192983e-05,
      "loss": 38.8933,
      "step": 50
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 7.521327018737793,
      "learning_rate": 3.9649122807017545e-05,
      "loss": 38.6053,
      "step": 60
    },
    {
      "epoch": 1.2280701754385965,
      "grad_norm": 8.696243286132812,
      "learning_rate": 3.789473684210527e-05,
      "loss": 36.826,
      "step": 70
    },
    {
      "epoch": 1.4035087719298245,
      "grad_norm": 9.466670036315918,
      "learning_rate": 3.6140350877192985e-05,
      "loss": 37.9292,
      "step": 80
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 8.473084449768066,
      "learning_rate": 3.43859649122807e-05,
      "loss": 36.0689,
      "step": 90
    },
    {
      "epoch": 1.7543859649122808,
      "grad_norm": 10.5242919921875,
      "learning_rate": 3.2631578947368426e-05,
      "loss": 35.9272,
      "step": 100
    },
    {
      "epoch": 1.9298245614035088,
      "grad_norm": 10.240266799926758,
      "learning_rate": 3.087719298245614e-05,
      "loss": 35.2782,
      "step": 110
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 10.16953182220459,
      "learning_rate": 2.9122807017543863e-05,
      "loss": 35.279,
      "step": 120
    },
    {
      "epoch": 2.280701754385965,
      "grad_norm": 10.565781593322754,
      "learning_rate": 2.7368421052631583e-05,
      "loss": 33.09,
      "step": 130
    },
    {
      "epoch": 2.456140350877193,
      "grad_norm": 12.192459106445312,
      "learning_rate": 2.5614035087719303e-05,
      "loss": 32.6993,
      "step": 140
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 13.363083839416504,
      "learning_rate": 2.385964912280702e-05,
      "loss": 33.1992,
      "step": 150
    },
    {
      "epoch": 2.807017543859649,
      "grad_norm": 10.785140037536621,
      "learning_rate": 2.2105263157894736e-05,
      "loss": 32.7841,
      "step": 160
    },
    {
      "epoch": 2.982456140350877,
      "grad_norm": 11.469747543334961,
      "learning_rate": 2.0350877192982456e-05,
      "loss": 30.7162,
      "step": 170
    },
    {
      "epoch": 3.1578947368421053,
      "grad_norm": 11.577704429626465,
      "learning_rate": 1.8596491228070176e-05,
      "loss": 31.9818,
      "step": 180
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 10.629278182983398,
      "learning_rate": 1.6842105263157896e-05,
      "loss": 30.8438,
      "step": 190
    },
    {
      "epoch": 3.5087719298245617,
      "grad_norm": 11.06326961517334,
      "learning_rate": 1.5087719298245615e-05,
      "loss": 29.3349,
      "step": 200
    },
    {
      "epoch": 3.6842105263157894,
      "grad_norm": 12.137163162231445,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 29.0597,
      "step": 210
    },
    {
      "epoch": 3.8596491228070176,
      "grad_norm": 13.470199584960938,
      "learning_rate": 1.1578947368421053e-05,
      "loss": 29.1352,
      "step": 220
    },
    {
      "epoch": 4.035087719298246,
      "grad_norm": 11.021369934082031,
      "learning_rate": 9.824561403508772e-06,
      "loss": 29.0592,
      "step": 230
    },
    {
      "epoch": 4.2105263157894735,
      "grad_norm": 12.137886047363281,
      "learning_rate": 8.070175438596492e-06,
      "loss": 28.8061,
      "step": 240
    },
    {
      "epoch": 4.385964912280702,
      "grad_norm": 12.00000286102295,
      "learning_rate": 6.315789473684211e-06,
      "loss": 28.0078,
      "step": 250
    },
    {
      "epoch": 4.56140350877193,
      "grad_norm": 13.172785758972168,
      "learning_rate": 4.5614035087719304e-06,
      "loss": 28.6443,
      "step": 260
    },
    {
      "epoch": 4.7368421052631575,
      "grad_norm": 14.48798942565918,
      "learning_rate": 2.8070175438596493e-06,
      "loss": 28.2575,
      "step": 270
    },
    {
      "epoch": 4.912280701754386,
      "grad_norm": 11.831256866455078,
      "learning_rate": 1.0526315789473685e-06,
      "loss": 29.6326,
      "step": 280
    }
  ],
  "logging_steps": 10,
  "max_steps": 285,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 211250640322560.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
